import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
import joblib
from src.data_loader import load_config


def handle_missing_values(df, numeric_cols):
    """X·ª≠ l√Ω gi√° tr·ªã thi·∫øu."""
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())
    df['has_preview'] = df['preview'].apply(lambda x: False if pd.isna(x) or x == 'no' else True)
    df['preview'] = df['preview'].fillna('').replace('no', '')
    df['img'] = df['img'].fillna('')
    df = df.dropna(subset=['name', 'artist', 'spotify_id'])
    return df

def handle_outliers(df):
    """X·ª≠ l√Ω gi√° tr·ªã b·∫•t th∆∞·ªùng."""
    cols_0_1 = ['danceability', 'energy', 'speechiness', 'acousticness', 
                'instrumentalness', 'liveness', 'valence',
                'acousticness_artist', 'danceability_artist', 'energy_artist',
                'instrumentalness_artist', 'liveness_artist', 'speechiness_artist', 
                'valence_artist']
    df[cols_0_1] = df[cols_0_1].clip(lower=0, upper=1)
    df['loudness'] = df['loudness'].clip(lower=-60, upper=0)
    return df

def normalize_features(df, numeric_cols, scaler_path):
    """Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng s·ªë."""
    scaler = StandardScaler()
    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
    joblib.dump(scaler, scaler_path)
    return df

def encode_categorical(df, encoder_path):
    """M√£ h√≥a c·ªôt artist."""
    le = LabelEncoder()
    df['artist_encoded'] = le.fit_transform(df['artist'])
    joblib.dump(le, encoder_path)
    return df

def create_new_features(df):
    """T·∫°o ƒë·∫∑c tr∆∞ng m·ªõi."""
    df['avg_danceability'] = (df['danceability'] + df['danceability_artist']) / 2
    df['avg_energy'] = (df['energy'] + df['energy_artist']) / 2
    return df

def preprocess_data(input_path, output_path, scaler_path, encoder_path):
    """Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v√† l∆∞u k·∫øt qu·∫£."""
    config = load_config()
    numeric_cols = config['features']['numeric_cols']

    df = pd.read_csv(input_path)

    # üî• L·ªçc ch·ªâ c√°c b√†i c√≥ preview link v√† c√≥ ·∫£nh
    df = df[(df['preview'].notna()) & (df['preview'] != 'no') & (df['preview'] != '')]
    df = df[df['img'].notna() & (df['img'] != '')]

    # üî• L·∫•y t·ªëi ƒëa 1500 b√†i
    if len(df) > 1500:
        df = df.sample(n=1500, random_state=42)

    # C√°c b∆∞·ªõc x·ª≠ l√Ω nh∆∞ c≈©
    df = handle_missing_values(df, numeric_cols)
    df = handle_outliers(df)
    df = df.drop_duplicates(subset=['spotify_id'], keep='first')
    df = normalize_features(df, numeric_cols, scaler_path)
    df = encode_categorical(df, encoder_path)
    df = create_new_features(df)

    df.to_csv(output_path, index=False)
    print(f"ƒê√£ l∆∞u d·ªØ li·ªáu v√†o {output_path}")
    return df

def main():
    """H√†m ch√≠nh ƒë·ªÉ ch·∫°y ti·ªÅn x·ª≠ l√Ω."""
    config = load_config()
    preprocess_data(
        input_path=config['data']['raw'],
        output_path=config['data']['processed'],
        scaler_path=config['models']['scaler'],
        encoder_path=config['models']['label_encoder']
    )


if __name__ == "__main__":
    main()